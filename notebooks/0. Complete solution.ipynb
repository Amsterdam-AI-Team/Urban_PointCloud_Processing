{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-interference",
   "metadata": {},
   "source": [
    "# Urban PointCloud Processing\n",
    "\n",
    "This notebook shows a \"complete solution\" in which a single point cloud file is automatically labeled using the various tools available in this repository. For clarity we skip [preprocessing of AHN data](1.%20AHN%20preprocessing.ipynb) and assume all necassary data files are already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "# Import modules.\n",
    "import time\n",
    "\n",
    "import src.fusion as fusion\n",
    "import src.region_growing as growing\n",
    "import src.utils.ahn_utils as ahn_utils\n",
    "from src.pipeline import Pipeline\n",
    "from src.utils.labels import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the file to process.\n",
    "tile_code = '2386_9702'\n",
    "\n",
    "in_file = '../datasets/pointcloud/filtered_' + tile_code + '.laz'\n",
    "out_file = '../datasets/pointcloud/complete_' + tile_code + '.laz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-softball",
   "metadata": {},
   "source": [
    "## Data Fusion\n",
    "\n",
    "First, we use data fusion to automatically label ground and building points.\n",
    "\n",
    "For details and more options, see [2. Data fusion](2.%20Data%20fusion.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder for the fusers.\n",
    "ahn_data_folder = '../datasets/ahn/'\n",
    "\n",
    "# Ground fuser using pre-processed AHN data.\n",
    "npz_ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_data_folder,\n",
    "                                   method='npz', target='ground', epsilon=0.2)\n",
    "# Building fuser using pre-processed AHN data.\n",
    "npz_building_fuser = fusion.AHNFuser(Labels.BUILDING, ahn_data_folder,\n",
    "                                     method='npz', target='building', epsilon=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-source",
   "metadata": {},
   "source": [
    "## Region Growing\n",
    "\n",
    "Then, we use region growing to refine the buildings. This will make sure that protruding elements such as balconies are labelled correctly.\n",
    "\n",
    "For details, installation instructions and more options, see [3. Region growing](3.%20Region%20growing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region growing with building points as initial seed points. \n",
    "exclude_labels = (Labels.GROUND,)\n",
    "building_grower = growing.LabelConnectedComp(Labels.BUILDING, exclude_labels,\n",
    "                                             octree_level=10, min_component_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-packaging",
   "metadata": {},
   "source": [
    "## Label car like objects\n",
    "Now, we divide the leftover points in clusters and determine car like objects. \n",
    "\n",
    "For details, installation instructions and more options, see [4. Label cars](4.%20Label%20cars.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File with road information from BGT.\n",
    "bgt_data_file = '../datasets/bgt/bgt_roads.csv'\n",
    "\n",
    "ahn_reader = ahn_utils.NPZReader(ahn_data_folder)\n",
    "\n",
    "# Car fuser using a clustering algorithm and BGT road data.\n",
    "car_fuser = fusion.CarFuser(Labels.CAR, ahn_reader, \n",
    "                         bgt_file=bgt_data_file, octree_level=10,\n",
    "                         min_component_size=100, max_above_ground=3,\n",
    "                         min_width_thresh=1.5, max_width_thresh=2.55,\n",
    "                         min_length_thresh=2.0, max_length_thresh=7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-durham",
   "metadata": {},
   "source": [
    "## Process the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up pipeline.\n",
    "process_sequence = (npz_ground_fuser, npz_building_fuser, building_grower, car_fuser)\n",
    "pipeline = Pipeline(process_sequence)\n",
    "\n",
    "start = time.time()\n",
    "# Process the file.\n",
    "pipeline.process_file(in_file, out_file)\n",
    "end = time.time()\n",
    "print(f'Tile labelled in {end-start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-welsh",
   "metadata": {},
   "source": [
    "## View the result (e.g. in CloudCompare)\n",
    "\n",
    "The final result can be viewed in CloudCompare. Open the out_file (e.g. datasets/pointcloud/labelled_2386_9702.laz) and change `Colors` from \"RGB\" to \"Scalar field\".\n",
    "\n",
    "The result should look like this:\n",
    "![Demo result](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing/raw/main/media/examples/demo_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-inside",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
