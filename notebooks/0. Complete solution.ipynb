{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-interference",
   "metadata": {},
   "source": [
    "# Urban PointCloud Processing\n",
    "\n",
    "This notebook shows a \"complete solution\" in which a single point cloud file is automatically labeled using the various tools available in this repository. For clarity we skip [preprocessing of AHN data](1.%20AHN%20preprocessing.ipynb) and assume all necassary data files are already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project src to path.\n",
    "import set_path\n",
    "\n",
    "# Import modules.\n",
    "import time\n",
    "\n",
    "import src.fusion as fusion\n",
    "import src.region_growing as growing\n",
    "import src.utils.ahn_utils as ahn_utils\n",
    "from src.pipeline import Pipeline\n",
    "from src.utils.labels import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the file to process.\n",
    "tile_code = '2386_9702'\n",
    "\n",
    "in_file = '../datasets/pointcloud/filtered_' + tile_code + '.laz'\n",
    "out_file = '../datasets/pointcloud/complete_' + tile_code + '.laz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-softball",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Fusion\n",
    "\n",
    "### Ground and Buildings\n",
    "First, we use data fusion to automatically label ground and building points.\n",
    "\n",
    "For details and more options, see [2. Data fusion](2.%20Data%20fusion.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder for the fusers.\n",
    "ahn_data_folder = '../datasets/ahn/'\n",
    "\n",
    "# Ground fuser using pre-processed AHN data.\n",
    "npz_ground_fuser = fusion.AHNFuser(Labels.GROUND, ahn_data_folder,\n",
    "                                   method='npz', target='ground', epsilon=0.2)\n",
    "# Building fuser using pre-processed AHN data.\n",
    "npz_building_fuser = fusion.AHNFuser(Labels.BUILDING, ahn_data_folder,\n",
    "                                     method='npz', target='building', epsilon=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-packaging",
   "metadata": {},
   "source": [
    "### Cars\n",
    "\n",
    "Then we label cars by searching for 'car-like' clusters above road segments.\n",
    "\n",
    "For details and on how to generate the BGT road csv file, see [4. Label cars](4.%20Label%20cars.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File with road information from BGT.\n",
    "bgt_data_file = '../datasets/bgt/bgt_roads_' + tile_code + '.csv'\n",
    "\n",
    "# We use AHN elevation data to determine whether objects are close enough to the ground.\n",
    "ahn_reader = ahn_utils.NPZReader(ahn_data_folder)\n",
    "\n",
    "# Car fuser using a clustering algorithm and BGT road data.\n",
    "car_fuser = fusion.CarFuser(Labels.CAR, ahn_reader, \n",
    "                            bgt_file=bgt_data_file, octree_level=10,\n",
    "                            min_component_size=100, max_above_ground=3,\n",
    "                            min_width_thresh=1.5, max_width_thresh=2.55,\n",
    "                            min_length_thresh=2.0, max_length_thresh=7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac6c70-c67c-440f-9c93-7790b172db05",
   "metadata": {},
   "source": [
    "### Pole-like objects\n",
    "\n",
    "Finally we look for 'pole-like' objects such as street lights and traffic signs.\n",
    "\n",
    "For details and more options, see [2. BGT point fusion](2.%20BGT%20point%20fusion.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0a685-2525-40ab-bd8f-eff7f94a97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File with <x,y> coordinates of pole-like objects.\n",
    "bgt_data_file = '../datasets/bgt/custom_points_' + tile_code + '.csv'\n",
    "\n",
    "# Parameter settings.\n",
    "light_params = {'seed_height': 2.25, 'min_points': 400, 'max_r': 0.2, 'label_height': 5.}\n",
    "sign_params = {'seed_height': 1.75, 'min_points': 200, 'max_r': 0.2, 'min_height': 1.2, 'z_max': 2., 'label_height': 3.}\n",
    "\n",
    "# Fusers for BGT point data.\n",
    "light_fuser = fusion.BGTPointFuser(Labels.STREET_LIGHT, bgt_type='lichtmast', bgt_file=bgt_data_file, ahn_reader=ahn_reader, params=light_params)\n",
    "sign_fuser = fusion.BGTPointFuser(Labels.TRAFFIC_SIGN, bgt_type='verkeersbord', bgt_file=bgt_data_file, ahn_reader=ahn_reader, params=sign_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-source",
   "metadata": {},
   "source": [
    "---\n",
    "## Region Growing\n",
    "\n",
    "### Buildings\n",
    "\n",
    "Then, we use region growing to refine the buildings. This will make sure that protruding elements such as balconies are labelled correctly.\n",
    "\n",
    "For details, installation instructions and more options, see [3. Region growing](3.%20Region%20growing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region growing with building points as initial seed points. \n",
    "exclude_labels = (Labels.GROUND,)\n",
    "building_grower = growing.LabelConnectedComp(Labels.BUILDING, exclude_labels,\n",
    "                                             octree_level=10, min_component_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec09ab7-c0d3-4e0f-9412-fd714c05e1d2",
   "metadata": {},
   "source": [
    "### Pole-like objects\n",
    "\n",
    "We also use region growing to refine the pole-like objects. We do this separately for the top and bottom since the best settings for each might differ.\n",
    "\n",
    "For details and more options, see [2. BGT point fusion](2.%20BGT%20point%20fusion.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1670c-58c8-476a-ae85-5b0ab7ec241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_top_params = {'plane_height': 3.25, 'threshold': 0.05}\n",
    "light_bottom_params = {'plane_height': 1.5, 'threshold': 0.5}\n",
    "\n",
    "sign_top_params = {'plane_height': 1.5, 'threshold': 0.05}\n",
    "sign_bottom_params = {'plane_height': 1.5, 'threshold': 0.5}\n",
    "\n",
    "light_grower = growing.TopBottomLCC(Labels.STREET_LIGHT, ahn_reader, \n",
    "                                    top_params=light_top_params, \n",
    "                                    bottom_params=light_bottom_params)\n",
    "sign_grower = growing.TopBottomLCC(Labels.TRAFFIC_SIGN, ahn_reader, \n",
    "                                   top_params=sign_top_params, \n",
    "                                   bottom_params=sign_bottom_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-durham",
   "metadata": {},
   "source": [
    "## Process the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up pipeline.\n",
    "process_sequence = (npz_ground_fuser, npz_building_fuser, light_fuser, sign_fuser, car_fuser,\n",
    "                    building_grower, light_grower, sign_grower)\n",
    "pipeline = Pipeline(process_sequence)\n",
    "\n",
    "start = time.time()\n",
    "# Process the file.\n",
    "pipeline.process_file(in_file, out_file)\n",
    "end = time.time()\n",
    "print(f'Tile labelled in {end-start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-welsh",
   "metadata": {},
   "source": [
    "## View the result (e.g. in CloudCompare)\n",
    "\n",
    "The final result can be viewed in CloudCompare. Open the out_file (e.g. datasets/pointcloud/labelled_2386_9702.laz) and change `Colors` from \"RGB\" to \"Scalar field\". For best results, use our [custom color scale](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing/raw/main/media/cc_color_scale.xml).\n",
    "\n",
    "The result should look like this:\n",
    "![Demo result](https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing/raw/main/media/examples/demo_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-inside",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
